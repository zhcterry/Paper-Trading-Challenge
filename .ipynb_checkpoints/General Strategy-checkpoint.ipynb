{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io.html import read_html\n",
    "import re\n",
    "import requests\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from math import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.investopedia.com/top-stocks-4581225\"\n",
    "\n",
    "content = requests.get(base_url)\n",
    "\n",
    "urls_raw = re.findall(\"<li class=\\\"journey-nav__sublist-item \\\">\\n.*\\n.*\\n\", content.text) \n",
    "\n",
    "urls=[]\n",
    "\n",
    "for url in urls_raw:\n",
    "    url_clean = re.findall(\"https.*\\\"\",url)\n",
    "    url_cleaner = url_clean[0][:-1]\n",
    "    urls.append(url_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_m = urls[0:10+1] + urls[18:]\n",
    "tables = []\n",
    "try:\n",
    "    for url in urls_m:\n",
    "        table = read_html(url)\n",
    "        tables.append(table)\n",
    "except Exception as e:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if very webpage follow the value, growth, momentum format.\n",
    "for table in tables:\n",
    "    if(len(table) != 3):\n",
    "        print(len(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_raw = []\n",
    "tags = []\n",
    "\n",
    "for table in tables:\n",
    "    for i in range(3):\n",
    "        stocks =  table[i].iloc[1:3+1,0]\n",
    "        identifier = stocks.name\n",
    "        identifier = identifier.split(\" \")\n",
    "        if(\"Value\" in identifier): identifier = [e for e in identifier if e not in {\"Best\",\"Stocks\"}]\n",
    "        if(\"Growing\" in identifier) : identifier = [e for e in identifier if e not in {\"Fastest\",\"Stocks\"}]\n",
    "        if(\"Momentum\" in identifier) : identifier = [e for e in identifier if e not in {\"with\",\"the\",\"Most\",\"Stocks\"}]\n",
    "\n",
    "        stocks_raw.append(stocks)\n",
    "        tags.append(identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_cleaned = []\n",
    "for i in range(len(stocks_raw)):\n",
    "    for j in range(len(stocks_raw[i])):\n",
    "        stocks_df = list(stocks_raw[i])[j]\n",
    "        stocks_cleaned.append([stocks_df,tags[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_rows = []\n",
    "\n",
    "for i in range(len(stocks_cleaned)):\n",
    "    stock = stocks_cleaned[i][0]\n",
    "    tag = stocks_cleaned[i][1].copy()\n",
    "    \n",
    "    stock_raw = stock.split(\" \")\n",
    "    stock_name = \" \".join(stock_raw[:-1])\n",
    "    stock_ticker = stock_raw[-1][1:-1]\n",
    "    # type: value,growing or momentum\n",
    "    if (\"Value\" in tag):\n",
    "        type_ = \"Value\"\n",
    "        tag.remove(\"Value\")\n",
    "    if (\"Growing\" in tag):\n",
    "        type_ = \"Growth\"\n",
    "        tag.remove(\"Growing\")\n",
    "    if (\"Momentum\" in tag):\n",
    "        type_ = \"Momentum\"\n",
    "        tag.remove(\"Momentum\")\n",
    "    \n",
    "    # Sub-categories\n",
    "    sub = \" \".join(tag)\n",
    "    stocks_rows.append([stock_name,stock_ticker,type_,sub])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_rows(lst):\n",
    "    types = ['Growth', 'Momentum', 'Value']\n",
    "    a = lst[0:2]\n",
    "    b = [int(lst[2] in type) for type in types]\n",
    "    c = [lst[3]]\n",
    "    return(a+b+c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_expanded = list(map(lambda x:expand_rows(x),stocks_rows))\n",
    "\n",
    "df_stocks = pd.DataFrame(stocks_expanded,columns=[\"stock\",\"ticker\",'is.Growth', 'is.Momentum', 'is.Value',\n",
    "                                                  \"Tag\"])\n",
    "\n",
    "df_stocks.loc[df_stocks.ticker == \"BRK.B\", 'ticker'] = \"BRK-B\"\n",
    "def convert_outliers(x):\n",
    "    words = x.split(\" \")\n",
    "    outlier_words = [\"Beer\", \"Coal\",\"Coffee\",\"Wind\",\"Copper\",\"Cosmetics\",\"Energy\",\"Railway\",\"Steel\"]\n",
    "    if(len(words) > 2):\n",
    "        for word in outlier_words:\n",
    "            if (word in outlier_words): return(word)\n",
    "            else: return(x)\n",
    "    else:\n",
    "        return(x)\n",
    "\n",
    "tags_cleaned = list(map(lambda x: convert_outliers(x),df_stocks[\"Tag\"]))\n",
    "\n",
    "df_stocks[\"Tag\"] = tags_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_int = df_stocks.groupby(df_stocks[\"ticker\"]).mean().round().astype(int)\n",
    "df_grouped_int.reset_index(level=0, inplace=True)\n",
    "df_grouped_char = df_stocks.groupby(['ticker']).agg({'Tag': ', '.join})\n",
    "df_grouped_char.reset_index(level=0, inplace=True)\n",
    "df = df_grouped_int.merge(df_grouped_char[[\"ticker\",\"Tag\"]], on = \"ticker\", how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  180 of 180 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = np.unique(df[\"ticker\"])\n",
    "maindata = yf.download(list(tickers))[\"Adj Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = maindata.dropna().pct_change().dropna()\n",
    "stock_volatility = data.std()\n",
    "stock_return = data.mean()\n",
    "sigma = data.cov()\n",
    "stocks = data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(data,minrisk_return):\n",
    "    # define variables\n",
    "    stock_volatility = data.std()\n",
    "    stock_return = data.mean()\n",
    "    sigma = data.cov()\n",
    "    stocks = data.columns\n",
    "    \n",
    "    m = gp.Model('portfolio')\n",
    "    n = len(df)\n",
    "\n",
    "    # Upper bound set to 0.1 to ensure a minimum of 10 stocks, to ensure diversification.\n",
    "    weights = pd.Series(m.addVars(stocks, vtype = \"S\", lb = 0.001, ub = 0.1, name = \"weights\"), index=stocks)\n",
    "\n",
    "    portfolio_risk = sigma.dot(weights).dot(weights)\n",
    "    portfolio_return = stock_return.dot(weights)\n",
    "    m.setObjective(portfolio_risk, GRB.MINIMIZE)\n",
    "    \n",
    "    m.addConstr(weights.sum() == 1, 'budget')\n",
    "    #Ensure a sizable stake in value stock for stability\n",
    "    m.addConstr(gp.quicksum(weights[i] * df[\"is.Value\"][i] for i in range(n)) >= 0.3, \"Value\")\n",
    "    #Given the current situation, our group would like to invest substaintiably into Tech, Alterntive Energy and Pharmaceutical    \n",
    "    checklist_favor = [int((\"Tech\" in df.Tag[i]) or (\"Alternative\" in df.Tag[i]) or (\"Pharmaceutical\" in df.Tag[i])) for i in range(len(df.Tag))]\n",
    "    m.addConstr(gp.quicksum(weights[i] * checklist_favor[i] for i in range(n)) >= 0.3, \"Situational\")\n",
    "\n",
    "    \n",
    "    m.addConstr(portfolio_return >= minrisk_return, 'target')\n",
    "\n",
    "    m.setParam('OutputFlag', 0) # don't print the whole Chunk out\n",
    "    \n",
    "    try: \n",
    "        m.optimize()\n",
    "        sharpe = portfolio_risk.getValue()/portfolio_return.getValue()\n",
    "        result = sharpe\n",
    "        weights_result = []\n",
    "        for weight in weights:\n",
    "            if weight.x > 0:\n",
    "                weights_result.append([weight.varname[8:-1],weight.x])\n",
    "                \n",
    "    except: \n",
    "        result = 0\n",
    "        weights_result = 0\n",
    "    m.reset()\n",
    "    return([result,weights_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(data):\n",
    "    data_ = data.iloc[np.random.randint(len(data), size=2520)]\n",
    "    stock_return = data_.mean()\n",
    "    ret = np.linspace(0,stock_return.max(), 500)\n",
    "    \n",
    "    sharpes = []\n",
    "    weights = []\n",
    "    \n",
    "    result = 1\n",
    "    i=0\n",
    "    \n",
    "    while (result > 0):\n",
    "        val = run_model(data_,ret[i])\n",
    "        i = i+1\n",
    "        result = val[0]\n",
    "        sharpes.append(val[0])\n",
    "        weights.append(val[1])\n",
    "    \n",
    "    \n",
    "    return([\n",
    "        max(sharpes),\n",
    "        weights[sharpes.index(max(sharpes))]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit sim(data) returns 58.8 s ± 3.43 s per loop , q per min, 20 min should be able to run 20 different tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take performance in term of returns in three scenarios: Good, Average and Bad\n",
    "    # Good: Top 28 Average Return of yr 2020\n",
    "    # Bad: Bottom 28 Average Return of yr 2020\n",
    "    # Average: Total Average Return of yr 2020 without the top 28 and bottom 28 returns\n",
    "\n",
    "# for i in range(20):\n",
    "#     best_sharpe\n",
    "\n",
    "best_sharpe, weights = run_model(data, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data.copy()\n",
    "data_test = data_test[\"2020-01-01\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = np.sum(data_test,axis=1).sort_values(ascending = False).index[0:28]\n",
    "bot = np.sum(data_test,axis=1).sort_values().index[0:28]\n",
    "\n",
    "data_top = data_test[data_test.index.isin(top)].mean()\n",
    "data_bot = data_test[data_test.index.isin(bot)].mean()\n",
    "data_average = data_test[~data_test.index.isin((list(top)+list(bot)))].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ret = 0\n",
    "for ticker, weight in weights:\n",
    "    total_ret = 1/3*(total_ret + data_top[ticker] * weight) + 1/3*(total_ret + data_bot[ticker] * weight) + 1/3*(total_ret + data_average[ticker] * weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [8:37:53<3:46:08, 1130.74s/it] "
     ]
    }
   ],
   "source": [
    "score = []\n",
    "weights_ = []\n",
    "for i in tqdm(range(20)):\n",
    "    best_sharpe, weights = sim(data)\n",
    "    total_ret = 0\n",
    "    for ticker, weight in weights:\n",
    "        # Given the uncertainty of the current climate, Our group decide to apply the naive method, simply giving an equal weightage to all three possible possibilities \n",
    "        total_ret = 1/3*(total_ret + data_top[ticker] * weight) + 1/3*(total_ret + data_bot[ticker] * weight) + 1/3*(total_ret + data_average[ticker] * weight)\n",
    "    score.append([total_ret])\n",
    "    weights_.append(weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['BE', 0.10017955296219426],\n",
       " ['CSIQ', 0.19982044703780572],\n",
       " ['JAG.TO', 0.10017955296219427],\n",
       " ['NVAX', 0.2],\n",
       " ['TRIL.TO', 0.2],\n",
       " ['WLL', 0.19982044703780574]]"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max([results[i][0] for i in range(len(results))])\n",
    "\n",
    "results[6][1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
