{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io.html import read_html\n",
    "import re\n",
    "import requests\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from math import *\n",
    "from tqdm import tqdm\n",
    "from pandas.core.common import flatten\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.investopedia.com/top-stocks-4581225\"\n",
    "\n",
    "content = requests.get(base_url)\n",
    "\n",
    "urls_raw = re.findall(\"<li class=\\\"journey-nav__sublist-item \\\">\\n.*\\n.*\\n\", content.text) \n",
    "\n",
    "urls=[]\n",
    "\n",
    "for url in urls_raw:\n",
    "    url_clean = re.findall(\"https.*\\\"\",url)\n",
    "    url_cleaner = url_clean[0][:-1]\n",
    "    urls.append(url_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_m = urls[0:10+1] + urls[18:]\n",
    "pages = []\n",
    "try:\n",
    "    for url in urls_m:\n",
    "        page = read_html(url)\n",
    "        pages.append(page)\n",
    "except Exception as e:\n",
    "    print(url)\n",
    "    \n",
    "# pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if very webpage follow the value, growth, momentum format.\n",
    "for page in pages:\n",
    "    if(len(page) != 3):\n",
    "        print(len(page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker(stocks_raw):\n",
    "    tickers = []\n",
    "    for i in range(len(stocks_raw)):\n",
    "        ticker_raw = stocks_raw.iloc[i]\n",
    "        ticker = re.findall(\"\\(.*\\)\",ticker_raw)[0].replace(\"(\",\"\").replace(\")\",\"\")\n",
    "        tickers.append(ticker)\n",
    "    return(tickers)\n",
    "\n",
    "def get_info(info_raw):\n",
    "    \n",
    "    check_value = [\"Value\"]\n",
    "    check_growth = [\"Growth\", \"Growing\", \"Least Profit Decline\"]\n",
    "    check_momentum = [\"Momentum\",\"Performance\"]\n",
    "    \n",
    "    check = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    if ([check  for word in check_value if re.findall(word,info_raw)] != []):\n",
    "        cat = \"Value\"\n",
    "    \n",
    "    elif ([\"1\" for word in check_growth if re.findall(word,info_raw)] != []):\n",
    "        cat = \"Growth\"\n",
    "    \n",
    "    elif ([\"1\" for word in check_momentum if re.findall(word,info_raw)] != []):\n",
    "        cat = \"Momentum\"\n",
    "    \n",
    "    return(cat,info_raw)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = []\n",
    "cats = []\n",
    "tags = []\n",
    "\n",
    "for page in pages:\n",
    "    tables = page\n",
    "    for table in tables:\n",
    "        stocks_raw = table.iloc[1:3+1,0]\n",
    "        info_raw = stocks_raw.name\n",
    "        ticker = get_ticker(stocks_raw)\n",
    "        cat, tag = get_info(info_raw)\n",
    "        \n",
    "        tickers.append(ticker)\n",
    "        cats.append(cat)\n",
    "        tags.append(tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame( \n",
    "    {\"ticker\" : tickers,\n",
    "    \"cat\" : cats,\n",
    "    \"tag\" : tags}\n",
    ")\n",
    "\n",
    "df = df.explode(\"ticker\").reset_index().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df.groupby(df[\"ticker\"])['cat'].apply(list)\n",
    "tag = df.groupby(df[\"ticker\"])['tag'].apply(list)\n",
    "\n",
    "for i in range(len(tag)):\n",
    "    val = tag[i]\n",
    "    val = [word.split(\" \") for word in val]\n",
    "    val = list(flatten(val))\n",
    "    tag[tag.index[i]] = val\n",
    "\n",
    "df = pd.concat([cat,tag],axis = 1)\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = []\n",
    "for ticker in df[\"ticker\"]:\n",
    "    if(ticker[-2:] == \".A\"):\n",
    "        tickers.append(ticker.replace(\".\",\"-\"))\n",
    "    else:\n",
    "        tickers.append(ticker)\n",
    "df['ticker'] = tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't invest in assets ending with .TO or .V\n",
    "\n",
    "tickers_tradable = []\n",
    "\n",
    "for ticker in df['ticker']:\n",
    "    if(ticker[-2:] != \".V\" and ticker[-3:] != \".TO\"):\n",
    "        tickers_tradable.append(ticker)\n",
    "        \n",
    "df_tradable = df[df[\"ticker\"].isin(tickers_tradable)]\n",
    "df_tradable = df_tradable.reset_index().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  161 of 161 completed\n"
     ]
    }
   ],
   "source": [
    "maindata = yf.download(list(df_tradable[\"ticker\"]),start = \"2010-01-01\")[\"Adj Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = maindata.dropna().pct_change().dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(data,minrisk_return):\n",
    "    # define variables\n",
    "    stock_volatility = data.std()\n",
    "    stock_return = data.mean()\n",
    "    sigma = data.cov()\n",
    "    stocks = data.columns\n",
    "    \n",
    "    m = gp.Model('portfolio')\n",
    "    n = len(df_tradable)\n",
    "\n",
    "    # Upper bound set to 0.1 to ensure a minimum of 10 stocks, to ensure diversification.\n",
    "    weights = pd.Series(m.addVars(stocks, vtype = \"S\", lb = 0.001, ub = 0.1, name = \"weights\"), index=stocks)\n",
    "\n",
    "    portfolio_risk = sigma.dot(weights).dot(weights)\n",
    "    portfolio_return = stock_return.dot(weights)\n",
    "    m.setObjective(portfolio_risk, GRB.MINIMIZE)\n",
    "    \n",
    "    m.addConstr(weights.sum() == 1, 'budget')\n",
    "    # Ensure a sizable stake in value stock for stability\n",
    "    checklist_cat = [int((\"Value\" in df_tradable.cat[i])) for i in range(len(df_tradable.cat))]\n",
    "    m.addConstr(gp.quicksum(weights[i] * checklist_cat[i] for i in range(n)) >= 0.3, \"Value\")\n",
    "    # Given the current situation, our group would like to invest substaintiably into Tech, Alterntive Energy and Pharmaceutical    \n",
    "    checklist_favor = [int((\"Tech\" in df_tradable.tag[i]) or (\"Alternative\" in df_tradable.tag[i]) or (\"Pharmaceutical\" in df_tradable.tag[i])) for i in range(len(df_tradable.tag))]\n",
    "    m.addConstr(gp.quicksum(weights[i] * checklist_favor[i] for i in range(n)) >= 0.3, \"Situational\")\n",
    "\n",
    "    \n",
    "    m.addConstr(portfolio_return >= minrisk_return, 'target')\n",
    "\n",
    "    m.setParam('OutputFlag', 0) # don't print the whole Chunk out\n",
    "    \n",
    "    try: \n",
    "        m.optimize()\n",
    "        sharpe = portfolio_risk.getValue()/portfolio_return.getValue()\n",
    "        result = sharpe\n",
    "        weights_result = []\n",
    "        for weight in weights:\n",
    "            if weight.x > 0:\n",
    "                weights_result.append([weight.varname[8:-1],weight.x])\n",
    "                \n",
    "    except: \n",
    "        result = 0\n",
    "        weights_result = 0\n",
    "    m.reset()\n",
    "    return([result,weights_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(data):\n",
    "    data_ = data.iloc[np.random.randint(len(data), size=2520)]\n",
    "    stock_return = data_.mean()\n",
    "    ret = np.linspace(0,stock_return.max(), 500)\n",
    "    \n",
    "    sharpes = []\n",
    "    weights = []\n",
    "    \n",
    "    result = 1\n",
    "    i=0\n",
    "    \n",
    "    while (result > 0):\n",
    "        val = run_model(data_,ret[i])\n",
    "        i = i+1\n",
    "        result = val[0]\n",
    "        sharpes.append(val[0])\n",
    "        weights.append(val[1])\n",
    "    \n",
    "    \n",
    "    return([\n",
    "        max(sharpes),\n",
    "        weights[sharpes.index(max(sharpes))]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using license file c:\\gurobi\\gurobi.lic\n",
      "Academic license - for non-commercial use only\n",
      "The slowest run took 21.70 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "5.37 s ± 4.3 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# %timeit sim(data) returns 9.59 s ± 3.33 s per loop , 6 per min, 10 min can sample 60 times\n",
    "%timeit sim(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data.copy()\n",
    "data_test = data_test[\"2020-01-01\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = np.sum(data_test,axis=1).sort_values(ascending = False).index[0:28]\n",
    "bot = np.sum(data_test,axis=1).sort_values().index[0:28]\n",
    "\n",
    "data_top = data_test[data_test.index.isin(top)].mean()\n",
    "data_bot = data_test[data_test.index.isin(bot)].mean()\n",
    "data_average = data_test[~data_test.index.isin((list(top)+list(bot)))].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [16:33<00:00, 16.56s/it]  \n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "weights_ = []\n",
    "for i in tqdm(range(60)):\n",
    "    best_sharpe, weights = sim(data)\n",
    "    total_ret = 0\n",
    "    for ticker, weight in weights:\n",
    "        # Given the uncertainty of the current climate, Our group decide to apply the naive method, simply giving an equal weightage to all three possible possibilities \n",
    "        total_ret = 1/3*(total_ret + data_top[ticker] * weight) + 1/3*(total_ret + data_bot[ticker] * weight) + 1/3*(total_ret + data_average[ticker] * weight)\n",
    "    score.append(total_ret)\n",
    "    weights_.append(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CSIQ', 0.1],\n",
       " ['CVNA', 0.1],\n",
       " ['DQ', 0.1],\n",
       " ['ENPH', 0.1],\n",
       " ['FSLY', 0.08955362782623981],\n",
       " ['JKS', 0.1],\n",
       " ['QDEL', 0.1],\n",
       " ['RUN', 0.1],\n",
       " ['SEDG', 0.1],\n",
       " ['TWLO', 0.010446372173760335],\n",
       " ['VSLR', 0.1]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_[score.index(max(score))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
